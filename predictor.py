# -*- coding: utf-8 -*-

import chainer
from chainer import report, training, Chain, datasets, iterators, optimizers
import chainer.functions as F
import chainer.links as L
from chainer.training import extensions
from chainer.datasets import tuple_dataset
from chainer import serializers

import collections

import numpy as np
import matplotlib.pyplot as plt
import soundfile as sf 
import sys

def opensound(file_path,length):
    # data : ã“ã“ã«wavãƒ‡ãƒ¼ã‚¿ãŒnumpy.ndarrayã¨ã—ã¦ä¿æŒã•ã‚Œã¾ã™ã€‚
    # sampling_rate : å¤§åŠã®wavéŸ³æºã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆã¯44.1kHzã§ã™
    # fmt : ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã¯ã ã„ãŸã„PCMã§ã—ã‚‡ã†
    data, sampling_rate = sf.read(file_path)

    NFFT = 1024 # ãƒ•ãƒ¬ãƒ¼ãƒ ã®å¤§ãã•
    OVERLAP = NFFT // 2 # çª“ã‚’ãšã‚‰ã—ãŸæ™‚ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã®é‡ãªã‚Šå…·åˆ. half shiftãŒä¸€èˆ¬çš„ã‚‰ã—ã„
    frame_length = data.shape[0] # wavãƒ•ã‚¡ã‚¤ãƒ«ã®å…¨ãƒ•ãƒ¬ãƒ¼ãƒ æ•°
    time_song = float(frame_length) / sampling_rate  # æ³¢å½¢é•·ã•(ç§’)
    time_unit = 1 / float(sampling_rate) # 1ã‚µãƒ³ãƒ—ãƒ«ã®é•·ã•(ç§’)
    #print("sampling rate", sampling_rate)

    # ğŸ’¥ 1.
    # FFTã®ãƒ•ãƒ¬ãƒ¼ãƒ ã®æ™‚é–“ã‚’æ±ºã‚ã¦ã„ãã¾ã™
    # time_rulerã«å„ãƒ•ãƒ¬ãƒ¼ãƒ ã®ä¸­å¿ƒæ™‚é–“ãŒå…¥ã£ã¦ã„ã¾ã™
    start = (NFFT / 2) * time_unit
    stop = time_song
    step =  (NFFT - OVERLAP) * time_unit
    time_ruler = np.arange(start, stop, step)

    # ğŸ’¥ 2.
    # çª“é–¢æ•°ã¯å‘¨æ³¢æ•°è§£åƒåº¦ãŒé«˜ã„ãƒãƒŸãƒ³ã‚°çª“ã‚’ç”¨ã„ã¾ã™
    window = np.hamming(NFFT)
    
    spec = np.zeros([len(time_ruler), 1 + int(NFFT / 2)]) #è»¢ç½®çŠ¶æ…‹ã§å®šç¾©åˆæœŸåŒ–
    pos = 0

    for fft_index in range(len(time_ruler)):
        # ğŸ’¥ 1.ãƒ•ãƒ¬ãƒ¼ãƒ ã®åˆ‡ã‚Šå‡ºã—ã¾ã™
        frame = data[pos:pos+NFFT]
        # ãƒ•ãƒ¬ãƒ¼ãƒ ãŒä¿¡å·ã‹ã‚‰åˆ‡ã‚Šå‡ºã›ãªã„æ™‚ã¯ã‚¢ã‚¦ãƒˆã§ã™
        if len(frame) == NFFT:
            # ğŸ’¥ 2.çª“é–¢æ•°ã‚’ã‹ã‘ã¾ã™
            windowed = window * frame
            # ğŸ’¥ 3.FFTã—ã¦å‘¨æ³¢æ•°æˆåˆ†ã‚’æ±‚ã‚ã¾ã™
            # rfftã ã¨éè² ã®å‘¨æ³¢æ•°ã®ã¿ãŒå¾—ã‚‰ã‚Œã¾ã™
            fft_result = np.fft.rfft(windowed)
            # ğŸ’¥ 4.å‘¨æ³¢æ•°ã«ã¯è™šæ•°æˆåˆ†ã‚’å«ã‚€ã®ã§çµ¶å¯¾å€¤ã‚’absã§æ±‚ã‚ã¦ã‹ã‚‰2ä¹—ã—ã¾ã™
            # ã‚°ãƒ©ãƒ•ã§è¦‹ã‚„ã™ãã™ã‚‹ãŸã‚ã«å¯¾æ•°ã‚’ã¨ã‚Šã¾ã™
            fft_data = np.log(np.abs(fft_result) ** 2)
            # fft_data = np.log(np.abs(fft_result))
            # fft_data = np.abs(fft_result) ** 2
            # fft_data = np.abs(fft_result)
            # ã“ã‚Œã§æ±‚ã‚ã‚‰ã‚Œã¾ã—ãŸã€‚ã‚ã¨ã¯specã«æ ¼ç´ã™ã‚‹ã ã‘ã§ã™
            for i in range(len(spec[fft_index])):
                spec[fft_index][-i-1] = fft_data[i]
                # ğŸ’¥ 4. çª“ã‚’ãšã‚‰ã—ã¦æ¬¡ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã¸
            pos += (NFFT - OVERLAP)

    ne=np.reshape(spec[:length*10],(length,10,513))

    ### ãƒ—ãƒ­ãƒƒãƒˆã—ã¾ã™
    # matplotlib.imshowã§ã¯extentã‚’æŒ‡å®šã—ã¦è»¸ã‚’æ±ºã‚ã‚‰ã‚Œã¾ã™ã€‚aspect="auto"ã§é©åˆ‡ãªã‚µã‚¤ã‚ºæ¯”ã«ãªã‚Šã¾ã™
    '''
    plt.imshow(ne[2].T, extent=[0, time_song, 0, sampling_rate/2], aspect="auto")
    #plt.imshow(spec.T, extent=[0, time_song, 0, sampling_rate/2], aspect="auto")
    plt.xlabel("time[s]")
    plt.ylabel("frequency[Hz]")
    plt.colorbar()
    plt.show()
    '''
    return ne

class CNN(Chain):  
    def __init__(self):
        super(CNN, self).__init__()
        with self.init_scope():
            self.cn1 = L.Convolution2D(1, 20, 3)
            self.cn2 = L.Convolution2D(20, 50, 3)
            self.fc1 = L.Linear(None, 500)
            self.fc2 = L.Linear(500, 4)

    def __call__(self, x):
        h1 = F.max_pooling_2d(F.relu(self.cn1(x)), 2)
        h2 = F.max_pooling_2d(F.relu(self.cn2(h1)), 2)
        h3 = F.dropout(F.relu(self.fc1(h2)))
        return self.fc2(h3)
    
args = sys.argv
    
test_x = opensound(args[1],80)
                    
test_x = test_x-np.min(test_x)
test_x = test_x/np.max(test_x)
test_x = test_x.astype(np.float32)
test_x = test_x.reshape([test_x.shape[0],1,10,513])  # å¿…ãšï¼ˆãƒ‡ãƒ¼ã‚¿ã®ç·æ•°, channelæ•°, ç¸¦, æ¨ªï¼‰ã®å½¢ã«ã—ã¦ãŠã
    
infer_net = CNN()
serializers.load_npz(
    'result/snapshot_iter_3372',
    infer_net, path='updater/model:main/predictor/')

with chainer.using_config('train', False), chainer.using_config('enable_backprop', False):
    y = infer_net(test_x).data
print(y)

c = collections.Counter(list(y.argmax(axis=1)))
print('äºˆæ¸¬ãƒ©ãƒ™ãƒ«:', y.argmax(axis=1))
print('äºˆæ¸¬é »åº¦:',c.most_common())


'''
#print(np.max(new),np.min(new),np.average(new))
# np.float 0.0-1.0ã« æ­£è¦åŒ–
train_x = train_x-np.min(train_x)
train_x = train_x/np.max(train_x)
train_x = train_x.astype(np.float32)

train_y = np.vstack((np.full((562,1),0),np.full((562,1),1)))
train_y = np.vstack((train_y,np.full((562,1),2)))
train_y = np.vstack((train_y,np.full((562,1),3)))
train_y = train_y.astype(np.int32)

test_x = np.vstack((opensound("01-10s.wav",93), opensound("02-10s.wav",93)))
test_x = np.vstack((test_x, opensound("03-10s.wav",93)))
test_x = np.vstack((test_x, opensound("paper-10s.wav",93)))

test_x = test_x-np.min(test_x)
test_x = test_x/np.max(test_x)
test_x = test_x.astype(np.float32)

test_y = np.vstack((np.full((93,1),0),np.full((93,1),1)))
test_y = np.vstack((test_y,np.full((93,1),2)))
test_y = np.vstack((test_y,np.full((93,1),3)))
test_y = test_y.astype(np.int32)

train_x = train_x.reshape([2248,1,10,513])  # å¿…ãšï¼ˆãƒ‡ãƒ¼ã‚¿ã®ç·æ•°, channelæ•°, ç¸¦, æ¨ªï¼‰ã®å½¢ã«ã—ã¦ãŠã
test_x = test_x.reshape([372,1,10,513])  # å¿…ãšï¼ˆãƒ‡ãƒ¼ã‚¿ã®ç·æ•°, channelæ•°, ç¸¦, æ¨ªï¼‰ã®å½¢ã«ã—ã¦ãŠã
train_y = train_y.reshape(2248)
test_y = test_y.reshape(372)
train = tuple_dataset.TupleDataset(train_x, train_y)
test = tuple_dataset.TupleDataset(test_x, test_y)
sys.exit()
model = L.Classifier(CNN())
optimizer = optimizers.Adam()
optimizer.setup(model)

train_iter = iterators.SerialIterator(train, batch_size=100)
test_iter = iterators.SerialIterator(test, batch_size=20, repeat=False, shuffle=False)

updater = training.StandardUpdater(train_iter, optimizer)
trainer = training.Trainer(updater, (150, 'epoch'), out='result')

trainer.extend(extensions.Evaluator(test_iter, model))
trainer.extend(extensions.LogReport())
trainer.extend(extensions.snapshot(), trigger=(10, 'epoch'))
trainer.extend(extensions.PrintReport(['epoch', 'main/accuracy', 'validation/main/accuracy']))
trainer.extend(extensions.ProgressBar())
trainer.run()
'''
